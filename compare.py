import torch
import torchvision.transforms as T
import torchvision.models as models
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import os
import threading

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU (NVIDIA) –∏–ª–∏ CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üîç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

# –ì–ª–∞–≤–Ω–∞—è –ø–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
root_folder = "./output/256"

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = models.segmentation.deeplabv3_resnet101(weights=None, num_classes=1)
checkpoint = torch.load("deeplabv3_model_epoch_260.pth", map_location=device)
filtered_checkpoint = {k: v for k, v in checkpoint.items() if "aux_classifier" not in k}
model.load_state_dict(filtered_checkpoint, strict=False)
model.to(device)
model.eval()

# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def preprocess_image(image_path):
    transform = T.Compose([
        T.Resize((256, 256)),  # –†–∞–∑–º–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    image = Image.open(image_path).convert("RGB").resize((256, 256))  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
    return transform(image).unsqueeze(0).to(device)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ GPU/CPU

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –∫—Ä–∞—Å–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
def filter_red_regions(output):
    red_mask = np.zeros((256, 256, 3), dtype=np.uint8)  # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—É—é –º–∞—Å–∫—É RGB
    red_mask[:, :, 0] = (output * 255).astype(np.uint8)  # –ö—Ä–∞—Å–Ω—ã–π –∫–∞–Ω–∞–ª
    return red_mask

# –§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def save_blended_image(folder_path, image_name, output):
    save_path = os.path.join(folder_path, image_name.replace(".png", "_p.png"))
    
    filtered_output = filter_red_regions(output)  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∫—Ä–∞—Å–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏
    
    Image.fromarray(filtered_output).resize((256,256),Image.LANCZOS).save(save_path);
    #fig, ax = plt.subplots(figsize=(2.56, 2.56), dpi=100)  # –ü—Ä–æ–ø–æ—Ä—Ü–∏–∏ –¥–ª—è 256x256
    #ax.imshow(filtered_output)
    #ax.axis("off")
    #plt.savefig(save_path, bbox_inches="tight", pad_inches=0, dpi=100)
    #plt.close(fig)
    
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {save_path}")

# –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤–æ –≤—Å–µ—Ö –ø–∞–ø–∫–∞—Ö –≤ —Ñ–æ–Ω–µ
def process_images():
    for subfolder in sorted(os.listdir(root_folder)):
        folder_path = os.path.join(root_folder, subfolder)
        if not os.path.isdir(folder_path):
            continue
       
        
        image_files = sorted([f for f in os.listdir(folder_path) if f.endswith(".png") and not f.endswith("_m.png") and not f.endswith("_p.png")])
        
        for image_name in image_files:
            image_path = os.path.join(folder_path, image_name)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_tensor = preprocess_image(image_path)

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                output = model(image_tensor)["out"].to(device)  # –§–æ—Ä–º–∞ (1, H, W)
                output = torch.sigmoid(output).squeeze().cpu().numpy()  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω—é—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (H, W)
                output = (output > 0.5).astype(np.uint8)  # –ë–∏–Ω–∞—Ä–∏–∑—É–µ–º

            # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–µ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –∫—Ä–∞—Å–Ω—ã–µ —Å–ª–µ–¥—ã)
            save_blended_image(folder_path, image_name, output)

# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ —Ñ–æ–Ω–µ
thread = threading.Thread(target=process_images)
thread.start()
